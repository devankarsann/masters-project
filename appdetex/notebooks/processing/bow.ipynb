{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYVUGSFLf_qE"
   },
   "source": [
    "## Libraries and Filesystem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqRQxTVbf39P",
    "outputId": "aecc64fb-dc6f-4d45-f5a3-98ec0b70cbfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dkarsann/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dkarsann/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (already have imported / processed dataframe and stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stopword lists from MastersProjectStopwords.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopwords = pickle.load(open(\"../../processed_files/stopwords/common_stopwords.pickle\", \"rb\"))\n",
    "corpus_stopwords = pickle.load(open(\"../../processed_files/stopwords/corpus_stopwords.pickle\", \"rb\"))\n",
    "combined_stopwords = pickle.load(open(\"../../processed_files/stopwords/combined_stopwords.pickle\", \"rb\"))\n",
    "corpus_bigrams = pickle.load(open(\"../../processed_files/stopwords/corpus_bigrams.pickle\", \"rb\"))\n",
    "corpus_trigrams = pickle.load(open(\"../../processed_files/stopwords/corpus_trigrams.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ6l1wSdkgzb"
   },
   "source": [
    "## Parsing and Processing Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>RAW_CONTENT</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x10-hk.com</td>\n",
       "      <td>automation@home » » | | quick find categories ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hupshenghware.com</td>\n",
       "      <td>captcha powered by imunify360 english hupsheng...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soponyonosnack.com</td>\n",
       "      <td>soponyonosnack.com currencies: rupiah language...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theromanticvineyard.com</td>\n",
       "      <td>wine train (blogroll) | the romantic vineyard ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eopticians.co.uk</td>\n",
       "      <td>brands, base curve (bc): 8.4, base curve (bc):...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DOMAIN                                        RAW_CONTENT  \\\n",
       "0               x10-hk.com  automation@home » » | | quick find categories ...   \n",
       "1        hupshenghware.com  captcha powered by imunify360 english hupsheng...   \n",
       "2       soponyonosnack.com  soponyonosnack.com currencies: rupiah language...   \n",
       "3  theromanticvineyard.com  wine train (blogroll) | the romantic vineyard ...   \n",
       "4         eopticians.co.uk  brands, base curve (bc): 8.4, base curve (bc):...   \n",
       "\n",
       "  LANGUAGE  \n",
       "0       en  \n",
       "1       en  \n",
       "2       en  \n",
       "3       en  \n",
       "4       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = pd.read_csv('../../processed_files/only_en.csv')\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging duplicate domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>RAW_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-my.com</td>\n",
       "      <td>0-my.com related searches: related searches:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bitz.com</td>\n",
       "      <td>error. page cannot be displayed. please contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01187.com</td>\n",
       "      <td>01187.com is available for purchase! - wwwv1.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>027.ir</td>\n",
       "      <td>027.ir - dns4.ir 027.ir hits: 7,267 under cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03h.org</td>\n",
       "      <td>february | 2014 | online marketing review sear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DOMAIN                                        RAW_CONTENT\n",
       "0    0-my.com       0-my.com related searches: related searches:\n",
       "1  00bitz.com  error. page cannot be displayed. please contac...\n",
       "2   01187.com  01187.com is available for purchase! - wwwv1.c...\n",
       "3      027.ir  027.ir - dns4.ir 027.ir hits: 7,267 under cons...\n",
       "4     03h.org  february | 2014 | online marketing review sear..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.DataFrame(df_en.groupby('DOMAIN')['RAW_CONTENT'].agg('sum')).reset_index()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12975"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_domain = df_merged['DOMAIN'].nunique()\n",
    "number_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12975, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>RAW_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-my.com</td>\n",
       "      <td>0-my.com related searches: related searches:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bitz.com</td>\n",
       "      <td>error. page cannot be displayed. please contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01187.com</td>\n",
       "      <td>01187.com is available for purchase! - wwwv1.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>027.ir</td>\n",
       "      <td>027.ir - dns4.ir 027.ir hits: 7,267 under cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03h.org</td>\n",
       "      <td>february | 2014 | online marketing review sear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DOMAIN                                        RAW_CONTENT\n",
       "0    0-my.com       0-my.com related searches: related searches:\n",
       "1  00bitz.com  error. page cannot be displayed. please contac...\n",
       "2   01187.com  01187.com is available for purchase! - wwwv1.c...\n",
       "3      027.ir  027.ir - dns4.ir 027.ir hits: 7,267 under cons...\n",
       "4     03h.org  february | 2014 | online marketing review sear..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ini_string = \"Geeks123for127geeks\"\n",
    "#  \n",
    "# printing initial ini_string\n",
    "#print(\"initial string : \", ini_string)\n",
    "#  \n",
    "# using translate and digits\n",
    "# to remove numeric digits from string\n",
    "#remove_digits = str.maketrans('', '', digits)\n",
    "#res = ini_string.translate(remove_digits)\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from string import digits\n",
    "from IPython.display import display\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "remove_punctuation = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(content):\n",
    "    \n",
    "    #--------remove domain name--------#\n",
    "    #processed = row['RAW_CONTENT'].replace(row['DOMAIN'], '')\n",
    "    \n",
    "    #--------no digits--------#\n",
    "    processed = content.translate(remove_digits)\n",
    "    #print('remove digits step')\n",
    "    #print(processed)\n",
    "    \n",
    "    #--------remove punction--------#\n",
    "    processed = processed.translate(remove_punctuation)\n",
    "    \n",
    "    #--------lower case--------#\n",
    "    processed = processed.lower()\n",
    "    #print('lowercase step')\n",
    "    #print(processed)\n",
    "    \n",
    "    #--------remove trigrams--------#\n",
    "    for trigram in corpus_trigrams:\n",
    "        processed = processed.replace(trigram.lower(), '')\n",
    "    #print('trigram step')\n",
    "    #print(processed)\n",
    "        \n",
    "    #--------remove bigrams--------#\n",
    "    for bigram in corpus_bigrams:\n",
    "        processed = processed.replace(bigram.lower(), '') \n",
    "    #print('bigram step')\n",
    "    #print(processed)\n",
    "    \n",
    "    #--------tokenize--------#\n",
    "    #print('tokenize step')\n",
    "    processed = tokenizer.tokenize(processed)\n",
    "    #print('tokenize step after')\n",
    "    #print(processed)\n",
    "    \n",
    "    #--------remove stopwords--------#\n",
    "    processed = [token for token in processed if token not in stop_words]\n",
    "    #print('stopwords step')\n",
    "    #print(processed)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_processed(content):\n",
    "    \n",
    "    #--------stem tokens--------#\n",
    "    processed = [ps.stem(token) for token in content]\n",
    "    #print('stem step')\n",
    "    #print(processed)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(content):\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged['RAW_CONTENT_PARSED'] = df_merged['RAW_CONTENT'].apply(lambda row: row.translate(remove_digits))\n",
    "#df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process(df_merged['RAW_CONTENT'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>RAW_CONTENT</th>\n",
       "      <th>RAW_CONTENT_PROCESSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-my.com</td>\n",
       "      <td>0-my.com related searches: related searches:</td>\n",
       "      <td>[mycom, related, searches, related, searches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bitz.com</td>\n",
       "      <td>error. page cannot be displayed. please contac...</td>\n",
       "      <td>[error, page, cannot, displayed, please, conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01187.com</td>\n",
       "      <td>01187.com is available for purchase! - wwwv1.c...</td>\n",
       "      <td>[com, vailable, purchase, wwwvcom, welcome, uu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>027.ir</td>\n",
       "      <td>027.ir - dns4.ir 027.ir hits: 7,267 under cons...</td>\n",
       "      <td>[ir, dnsir, ir, hits, construction, coming, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03h.org</td>\n",
       "      <td>february | 2014 | online marketing review sear...</td>\n",
       "      <td>[february, online, marketing, review, search, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DOMAIN                                        RAW_CONTENT  \\\n",
       "0    0-my.com       0-my.com related searches: related searches:   \n",
       "1  00bitz.com  error. page cannot be displayed. please contac...   \n",
       "2   01187.com  01187.com is available for purchase! - wwwv1.c...   \n",
       "3      027.ir  027.ir - dns4.ir 027.ir hits: 7,267 under cons...   \n",
       "4     03h.org  february | 2014 | online marketing review sear...   \n",
       "\n",
       "                               RAW_CONTENT_PROCESSED  \n",
       "0      [mycom, related, searches, related, searches]  \n",
       "1  [error, page, cannot, displayed, please, conta...  \n",
       "2  [com, vailable, purchase, wwwvcom, welcome, uu...  \n",
       "3  [ir, dnsir, ir, hits, construction, coming, so...  \n",
       "4  [february, online, marketing, review, search, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['RAW_CONTENT_PROCESSED'] = df_merged['RAW_CONTENT'].apply(lambda row: process(row))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>RAW_CONTENT</th>\n",
       "      <th>RAW_CONTENT_PROCESSED</th>\n",
       "      <th>RAW_CONTENT_PROCESSED_STEMMED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-my.com</td>\n",
       "      <td>0-my.com related searches: related searches:</td>\n",
       "      <td>[mycom, related, searches, related, searches]</td>\n",
       "      <td>[mycom, relat, search, relat, search]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bitz.com</td>\n",
       "      <td>error. page cannot be displayed. please contac...</td>\n",
       "      <td>[error, page, cannot, displayed, please, conta...</td>\n",
       "      <td>[error, page, cannot, display, pleas, contact,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01187.com</td>\n",
       "      <td>01187.com is available for purchase! - wwwv1.c...</td>\n",
       "      <td>[com, vailable, purchase, wwwvcom, welcome, uu...</td>\n",
       "      <td>[com, vailabl, purchas, wwwvcom, welcom, uunic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>027.ir</td>\n",
       "      <td>027.ir - dns4.ir 027.ir hits: 7,267 under cons...</td>\n",
       "      <td>[ir, dnsir, ir, hits, construction, coming, so...</td>\n",
       "      <td>[ir, dnsir, ir, hit, construct, come, soon, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03h.org</td>\n",
       "      <td>february | 2014 | online marketing review sear...</td>\n",
       "      <td>[february, online, marketing, review, search, ...</td>\n",
       "      <td>[februari, onlin, market, review, search, rece...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DOMAIN                                        RAW_CONTENT  \\\n",
       "0    0-my.com       0-my.com related searches: related searches:   \n",
       "1  00bitz.com  error. page cannot be displayed. please contac...   \n",
       "2   01187.com  01187.com is available for purchase! - wwwv1.c...   \n",
       "3      027.ir  027.ir - dns4.ir 027.ir hits: 7,267 under cons...   \n",
       "4     03h.org  february | 2014 | online marketing review sear...   \n",
       "\n",
       "                               RAW_CONTENT_PROCESSED  \\\n",
       "0      [mycom, related, searches, related, searches]   \n",
       "1  [error, page, cannot, displayed, please, conta...   \n",
       "2  [com, vailable, purchase, wwwvcom, welcome, uu...   \n",
       "3  [ir, dnsir, ir, hits, construction, coming, so...   \n",
       "4  [february, online, marketing, review, search, ...   \n",
       "\n",
       "                       RAW_CONTENT_PROCESSED_STEMMED  \n",
       "0              [mycom, relat, search, relat, search]  \n",
       "1  [error, page, cannot, display, pleas, contact,...  \n",
       "2  [com, vailabl, purchas, wwwvcom, welcom, uunic...  \n",
       "3  [ir, dnsir, ir, hit, construct, come, soon, ho...  \n",
       "4  [februari, onlin, market, review, search, rece...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['RAW_CONTENT_PROCESSED_STEMMED'] = df_merged['RAW_CONTENT_PROCESSED'].apply(lambda row: stem_processed(row))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../processed_files/df_merged.pickle', 'wb') as file:\n",
    "    pickle.dump(df_merged, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.head().style.set_properties(subset=['RAW_CONTENT'], **{'width-min': '100px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 µs, sys: 750 µs, total: 834 µs\n",
      "Wall time: 1.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#vect = CountVectorizer(tokenizer=process)\n",
    "vect = CountVectorizer(tokenizer = dummy, preprocessor = dummy)\n",
    "#corpus = df_merged['RAW_CONTENT'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not stemmed\n",
    "corpus = df_merged['RAW_CONTENT_PROCESSED'].tolist()\n",
    "BOW = vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmed\n",
    "corpus_stemmed = df_merged['RAW_CONTENT_PROCESSED_STEMMED'].tolist()\n",
    "BOW_stemmed = vect.fit_transform(corpus_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_pd = pd.DataFrame(BOW.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_stemmed_pd = pd.DataFrame(BOW_stemmed.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow_mat = np.matrix(BOW.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12975, 310919)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow_stemmed_mat = np.matrix(bow_pd.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12975, 273168)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_stemmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(BOW_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##np.save('../../processed_files/bow_matrix.npy', bow_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##np.save('../../processed_files/bow_stemmed_matrix.npy', bow_stemmed_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('../../processed_files/bow/bow_matrix.npz', BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('../../processed_files/bow/stemmed_bow_matrix.npz', BOW_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../processed_files/bow.pickle', 'wb') as file:\n",
    "#    pickle.dump(bow_mat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../processed_files/bow_stemmed.pickle', 'wb') as file:\n",
    "#    pickle.dump(bow_stemmed_mat, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating LDA Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#lda_10 = LatentDirichletAllocation(n_components = 10, random_state = 0)\n",
    "#LDA_10_mat = lda_10.fit_transform(BOW_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#lda_25 = LatentDirichletAllocation(n_components = 25, random_state = 0)\n",
    "#LDA_25_mat = lda_25.fit_transform(BOW_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#lda_50 = LatentDirichletAllocation(n_components = 50, random_state = 0)\n",
    "#LDA_50_mat = lda_50.fit_transform(BOW_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(LDA_10_mat.shape)\n",
    "#print(LDA_25_mat.shape)\n",
    "#print(LDA_50_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA_10_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA_25_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA_50_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_10 = LatentDirichletAllocation(n_components=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#LDA_mat_10 = lda_10.fit_transform(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA_mat_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA_mat_10[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../processed_files/LDA_10_matrix.pickle', 'wb') as file:\n",
    "#    pickle.dump(LDA_10_mat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../processed_files/LDA_25_matrix.pickle', 'wb') as file:\n",
    "#    pickle.dump(LDA_25_mat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../processed_files/LDA_50_matrix.pickle', 'wb') as file:\n",
    "#    pickle.dump(LDA_50_mat, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating TFIDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if self.count_vec is None:\n",
    "#    cv = CountVec()\n",
    "#    self.count_vec = cv.countvec(self.processed_tokens)\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#tf_idf_mat = tfidf_transformer.fit_transform(self.count_vec)\n",
    "#return tf_idf_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MastersProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
